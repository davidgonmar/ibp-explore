{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyNV+iDCgsw/cTH1phc/RStR"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pb8evIHdJv1o"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "Z_DIM = 64\n",
        "BETA = 1e-1\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 128\n",
        "LR = 1e-3\n",
        "SEED = 42\n",
        "NUM_WORKERS = 2\n",
        "MC_EVAL = 1\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "DATA_ROOT = \"./data\"\n",
        "IN_DIM = 28 * 28\n",
        "NUM_CLASSES = 10\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_all(s: int) -> None:\n",
        "    random.seed(s)\n",
        "    torch.manual_seed(s)\n",
        "\n",
        "class MLPEncoder(nn.Module):\n",
        "    def __init__(self, in_dim: int, z_dim: int, hidden=(512, 256)) -> None:\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        last = in_dim\n",
        "        for h in hidden:\n",
        "            layers += [nn.Linear(last, h), nn.ReLU(inplace=True)]\n",
        "            last = h\n",
        "        self.net = nn.Sequential(*layers)\n",
        "        self.mu = nn.Linear(last, z_dim)\n",
        "        self.logvar = nn.Linear(last, z_dim)\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        h = self.net(x)\n",
        "        return self.mu(h), self.logvar(h)\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, z_dim: int, num_classes: int) -> None:\n",
        "        super().__init__()\n",
        "        self.head = nn.Linear(z_dim, num_classes)\n",
        "\n",
        "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
        "        return self.head(z)\n",
        "\n",
        "class VIB(nn.Module):\n",
        "    def __init__(self, in_dim: int, z_dim: int, num_classes: int, hidden=(512, 256)) -> None:\n",
        "        super().__init__()\n",
        "        self.encoder = MLPEncoder(in_dim, z_dim, hidden)\n",
        "        self.classifier = Classifier(z_dim, num_classes)\n",
        "\n",
        "    @staticmethod\n",
        "    def reparam(mu: torch.Tensor, logvar: torch.Tensor) -> torch.Tensor:\n",
        "        std = (0.5 * logvar).exp()\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    @staticmethod\n",
        "    def kl(mu: torch.Tensor, logvar: torch.Tensor) -> torch.Tensor:\n",
        "        return 0.5 * (mu.pow(2) + logvar.exp() - 1.0 - logvar).sum(dim=1)\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        mu, logvar = self.encoder(x)\n",
        "        z = self.reparam(mu, logvar)\n",
        "        logits = self.classifier(z)\n",
        "        return logits, mu, logvar\n",
        "\n",
        "def get_mnist():\n",
        "    t = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda t: t.view(-1))])\n",
        "    tr = datasets.MNIST(DATA_ROOT, train=True, download=True, transform=t)\n",
        "    te = datasets.MNIST(DATA_ROOT, train=False, download=True, transform=t)\n",
        "    in_dim = 28 * 28\n",
        "    num_classes = 10\n",
        "    tr_loader = DataLoader(tr, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "    te_loader = DataLoader(te, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "    return tr_loader, te_loader, in_dim, num_classes\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model: VIB, loader: DataLoader):\n",
        "    model.eval()\n",
        "    ce_list = []\n",
        "    kl_list = []\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for x, y in loader:\n",
        "        x = x.to(DEVICE)\n",
        "        y = y.to(DEVICE)\n",
        "        logits_acc = 0\n",
        "        kl_acc = 0\n",
        "        for _ in range(max(1, MC_EVAL)):\n",
        "            logits, mu, logvar = model(x)\n",
        "            logits_acc = logits_acc + logits\n",
        "            kl_acc = kl_acc + VIB.kl(mu, logvar)\n",
        "        logits = logits_acc / max(1, MC_EVAL)\n",
        "        kl = kl_acc / max(1, MC_EVAL)\n",
        "        ce = F.cross_entropy(logits, y, reduction=\"none\")\n",
        "        ce_list.append(ce.detach())\n",
        "        kl_list.append(kl.detach())\n",
        "        pred = logits.argmax(1)\n",
        "        correct += (pred == y).sum().item()\n",
        "        total += y.size(0)\n",
        "    ce = torch.cat(ce_list).mean().item()\n",
        "    kl = torch.cat(kl_list).mean().item()\n",
        "    acc = correct / max(1, total)\n",
        "    return ce, kl, acc\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_mi_gaussian(z1: torch.Tensor, z2: torch.Tensor, eps: float = 1e-5) -> float:\n",
        "    \"\"\"\n",
        "    z1: [N, d1] tensor of samples from model 1\n",
        "    z2: [N, d2] tensor of samples from model 2\n",
        "    Returns: scalar MI estimate (nats) under a joint-Gaussian plug-in model.\n",
        "    \"\"\"\n",
        "    assert z1.shape[0] == z2.shape[0]\n",
        "    X = torch.cat([z1, z2], dim=1)\n",
        "    X = X - X.mean(dim=0, keepdim=True)\n",
        "\n",
        "    N = X.shape[0]\n",
        "    Sigma = (X.T @ X) / (N - 1)\n",
        "    d1 = z1.shape[1]\n",
        "\n",
        "    eye = torch.eye(Sigma.shape[0], device=Sigma.device)\n",
        "    Sigma = Sigma + eps * eye\n",
        "\n",
        "    S11 = Sigma[:d1, :d1]\n",
        "    S22 = Sigma[d1:, d1:]\n",
        "\n",
        "    # logdet sigma\n",
        "    sign_full, logdet_full = torch.slogdet(Sigma)\n",
        "    sign_11, logdet_11 = torch.slogdet(S11)\n",
        "    sign_22, logdet_22 = torch.slogdet(S22)\n",
        "    if (sign_full <= 0) or (sign_11 <= 0) or (sign_22 <= 0):\n",
        "        raise ValueError(\"Nonâ€“PD covariance\")\n",
        "\n",
        "    mi = 0.5 * (logdet_11 + logdet_22 - logdet_full)  # nats\n",
        "    return mi.item()\n",
        "\n"
      ],
      "metadata": {
        "id": "ek1i33utJ4j4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PhALdygHJ9nD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train teacher\n",
        "\n",
        "seed_all(SEED)\n",
        "tr_loader, te_loader, IN_DIM, NUM_CLASSES = get_mnist()\n",
        "model = VIB(IN_DIM, Z_DIM, NUM_CLASSES).to(DEVICE)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "train_acc, val_acc = [], []\n",
        "train_loss, val_loss = [], []\n",
        "train_ixz, val_ixz = [], []\n",
        "train_iyz, val_iyz = [], []\n",
        "H_Y = math.log(NUM_CLASSES) # we assume classes follow an uniform dist\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    model.train()\n",
        "    p = tqdm(tr_loader, desc=f\"epoch {epoch}/{EPOCHS}\")\n",
        "    ce_sum, kl_sum, loss_sum, correct, total, n_batches = 0.0, 0.0, 0.0, 0, 0, 0\n",
        "    for x, y in p:\n",
        "        x = x.to(DEVICE)\n",
        "        y = y.to(DEVICE)\n",
        "        logits, mu, logvar = model(x)\n",
        "        ce = F.cross_entropy(logits, y)\n",
        "        kl = VIB.kl(mu, logvar).mean()\n",
        "        loss = ce + BETA * kl\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        p.set_postfix(loss=loss.item(), ce=ce.item(), kl=kl.item())\n",
        "        ce_sum += ce.item()\n",
        "        kl_sum += kl.item()\n",
        "        loss_sum += loss.item()\n",
        "        pred = logits.argmax(1)\n",
        "        correct += (pred == y).sum().item()\n",
        "        total += y.size(0)\n",
        "        n_batches += 1\n",
        "    ce_tr = ce_sum / n_batches\n",
        "    kl_tr = kl_sum / n_batches\n",
        "    loss_tr = loss_sum / n_batches\n",
        "    acc_tr = correct / total\n",
        "    train_ixz.append(kl_tr)\n",
        "    train_iyz.append(H_Y - ce_tr)\n",
        "    train_loss.append(loss_tr)\n",
        "    train_acc.append(acc_tr)\n",
        "\n",
        "    ce_v, kl_v, acc_v = evaluate(model, te_loader)\n",
        "    val_ixz.append(kl_v)\n",
        "    val_iyz.append(H_Y - ce_v)\n",
        "    val_loss.append(ce_v + BETA * kl_v)\n",
        "    val_acc.append(acc_v)\n",
        "\n",
        "    print(f\"val_acc={acc_v*100:.2f}% val_CE={ce_v:.4f} Ixz={kl_v:.4f} Iyz={H_Y - ce_v:.4f}\")\n",
        "\n",
        "# save teacher\n",
        "torch.save({\n",
        "    \"model\": model.state_dict(),\n",
        "    \"opt\": opt.state_dict(),\n",
        "    \"ixz\": train_ixz,\n",
        "    \"iyz\": train_iyz,\n",
        "    \"loss\": train_loss,\n",
        "    \"acc\": train_acc,\n",
        "}, \"teacher.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcnWybQGJ_Ec",
        "outputId": "ea406c81-e612-498c-d201-b0c0915d746e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 1/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:04<00:00, 108.70it/s, ce=0.666, kl=4.56, loss=1.12]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_acc=87.60% val_CE=0.4793 Ixz=4.5962 Iyz=1.8233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 2/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:04<00:00, 113.62it/s, ce=0.268, kl=4.82, loss=0.75]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_acc=89.42% val_CE=0.3841 Ixz=4.8015 Iyz=1.9185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 3/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:04<00:00, 113.06it/s, ce=0.385, kl=5.22, loss=0.907]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_acc=90.77% val_CE=0.3281 Ixz=5.1142 Iyz=1.9744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 4/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:04<00:00, 110.18it/s, ce=0.238, kl=4.81, loss=0.719]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_acc=90.75% val_CE=0.3232 Ixz=4.8579 Iyz=1.9794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 5/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:03<00:00, 118.11it/s, ce=0.235, kl=4.98, loss=0.733]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_acc=91.23% val_CE=0.2938 Ixz=4.9091 Iyz=2.0088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 6/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:04<00:00, 114.41it/s, ce=0.239, kl=4.87, loss=0.726]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_acc=91.44% val_CE=0.2935 Ixz=4.8139 Iyz=2.0090\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 7/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:03<00:00, 120.40it/s, ce=0.302, kl=4.78, loss=0.78]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_acc=90.93% val_CE=0.3033 Ixz=4.7021 Iyz=1.9993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 8/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:04<00:00, 114.86it/s, ce=0.355, kl=4.64, loss=0.819]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_acc=90.95% val_CE=0.3058 Ixz=4.4485 Iyz=1.9968\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 9/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:04<00:00, 114.20it/s, ce=0.274, kl=4.66, loss=0.741]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_acc=92.02% val_CE=0.2691 Ixz=4.6689 Iyz=2.0334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 10/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:03<00:00, 118.03it/s, ce=0.291, kl=4.68, loss=0.76]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_acc=91.86% val_CE=0.2741 Ixz=4.5537 Iyz=2.0284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 11/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:04<00:00, 115.37it/s, ce=0.297, kl=4.86, loss=0.783]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_acc=92.77% val_CE=0.2536 Ixz=4.8415 Iyz=2.0489\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 12/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:04<00:00, 115.55it/s, ce=0.257, kl=4.71, loss=0.728]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_acc=93.33% val_CE=0.2390 Ixz=4.6283 Iyz=2.0636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 13/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:03<00:00, 118.25it/s, ce=0.114, kl=4.59, loss=0.574]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_acc=92.82% val_CE=0.2573 Ixz=4.5191 Iyz=2.0453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 14/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:04<00:00, 112.18it/s, ce=0.136, kl=4.55, loss=0.59]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_acc=93.59% val_CE=0.2344 Ixz=4.4530 Iyz=2.0682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 15/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:03<00:00, 117.51it/s, ce=0.104, kl=4.36, loss=0.539]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_acc=93.36% val_CE=0.2353 Ixz=4.3354 Iyz=2.0673\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 16/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:04<00:00, 112.16it/s, ce=0.198, kl=4.34, loss=0.632]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_acc=93.58% val_CE=0.2287 Ixz=4.3471 Iyz=2.0739\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 17/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:04<00:00, 115.88it/s, ce=0.177, kl=4.16, loss=0.593]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_acc=93.88% val_CE=0.2228 Ixz=4.1512 Iyz=2.0798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 18/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:03<00:00, 118.05it/s, ce=0.144, kl=4.32, loss=0.576]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_acc=94.62% val_CE=0.2145 Ixz=4.1493 Iyz=2.0881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 19/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:03<00:00, 117.93it/s, ce=0.0518, kl=4.25, loss=0.477]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_acc=94.04% val_CE=0.2154 Ixz=4.1108 Iyz=2.0872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 20/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:03<00:00, 119.43it/s, ce=0.111, kl=4.2, loss=0.531]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_acc=94.74% val_CE=0.1992 Ixz=4.1287 Iyz=2.1034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have two models $S(X, W_s) = D_s(z_s \\sim \\mathcal{N}(\\mu_s(X), \\log \\sigma_s(X)))$ and $T(X, W_t) = D_t(z_t \\sim \\mathcal{N}(\\mu_t(X), \\log \\sigma_t(X)))$.\n",
        "\n",
        "We have that\n",
        "$$\n",
        "I(Z_t; Z_s) = \\mathbb{E}[\\log(p(Z_t|Z_s)) - \\log(p(Z_t))] = \\\\ H(p(Z_t)) - \\mathbb{E}[\\log \\left(\\frac{p(Z_t|Z_s)}{q(Z_t|Z_s)}\\right)] + \\mathbb{E}[ \\log q(Z_t|Z_s)] = \\\\ H(Z_t) + \\mathbb{E}[ \\log q(Z_t|Z_s)] + \\mathbb{E}_{p(Z_s)} [D_{KL}(p(Z_t|Z_s) \\| q(Z_t|Z_s))].\n",
        "$$\n",
        "\n",
        "Suppose that we want to maximize $I(Z_t; Z_s)$ (with $Z_s$ as a variable). That is equivalent to maximizing\n",
        "$$\n",
        "\\mathbb{E}[ \\log q(Z_t|Z_s)] + \\mathbb{E}_{p(Z_s)} [D_{KL}(p(Z_t|Z_s) \\| q(Z_t|Z_s))].\n",
        "$$\n",
        "\n",
        "Given the preceding equalities, we can just minimize $-\\mathbb{E}[ \\log q(Z_t|Z_s)] = O(s, q)$ by jointly optimizing $Z_s$ and $q$.\n",
        "\n",
        "It is also easy to see that $O(s, q) \\geq H(Z_t|Z_s)$, so by minimizing $O$, we minimize the entropy (we assume that $q$ has good representation capabilities).\n",
        "\n",
        "Note that those variables are gaussian and nondeterministic, so that we can have nice behavior. How can that be related to the IBP? If we assume it is true, and our teacher is nice, then we can say that our teacher is good at the objective\n",
        "$$\n",
        "\\max_{Z_t} I(Y; Z_t) - \\beta I(X; Z_t).\n",
        "$$\n",
        "\n",
        "We want our student to also be good at it. We can cast that as wanting to minimize\n",
        "$$\n",
        "|I(Y; Z_t) - I(Y; S_t)|,\\\\\n",
        "|I(X; Z_t) - I(Y; S_t)|.\n",
        "$$\n",
        "\n",
        "We claim that maximizing $I(Z_t; Z_s)$ can achieve that. Note that\n",
        "$$\n",
        "I(Y; Z_t, Z_s) = I(Y; Z_t | Z_s) + I(Y; Z_s) \\\\\n",
        "I(Y; Z_t, Z_s) = I(Y; Z_s | Z_t) + I(Y; Z_t)\n",
        "$$\n",
        "so\n",
        "$$\n",
        "I(Y; Z_s) = I(Y; Z_t, Z_s) - I(Y; Z_t | Z_s) \\\\\n",
        "I(Y; Z_t) = I(Y; Z_t, Z_s) - I(Y; Z_s | Z_t)\n",
        "$$\n",
        "hence\n",
        "$$\n",
        "I(Y; Z_t)  - I(Y; Z_s)   = I(Y; Z_s, Z_t) - I(Y; Z_s | Z_t) - I(Y; Z_s, Z_t) + I(Y; Z_t | Z_s) = \\\\ I(Y; Z_t | Z_s) - I(Y; Z_s | Z_t) \\leq I(Y; Z_t | Z_s) = H(Z_t|Z_s) - H(Z_t|Y, Z_s) \\leq H(Z_t|Z_s).\n",
        "$$\n",
        "(the last equality assumes positive entropy. Can I do that? I think so, as Z_s has noise).\n",
        "\n",
        "Same can be done with $X$. The thing is that this can just make $Z_s$'s entropy/MI with $X$ and $Y$ big and miss the point.\n"
      ],
      "metadata": {
        "id": "VRlnjnnNRO6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "DEVICE = globals().get(\"DEVICE\", \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "EPOCHS = 100 #globals().get(\"EPOCHS\", 20)\n",
        "IN_DIM = globals()[\"IN_DIM\"]\n",
        "NUM_CLASSES = globals()[\"NUM_CLASSES\"]\n",
        "Z_DIM = globals()[\"Z_DIM\"]\n",
        "Z_DIM_STUDENT = globals().get(\"Z_DIM_STUDENT\", Z_DIM)\n",
        "LR_STUDENT = globals().get(\"LR_STUDENT\", 1e-3)\n",
        "LR_Q = globals().get(\"LR_Q\", 1e-3)\n",
        "BETA = globals().get(\"BETA\", 1e-2)\n",
        "EPS = 1e-5\n",
        "\n",
        "def collect_mu_y(model, loader, device=DEVICE, max_batches=None):\n",
        "    model.eval(); mus, ys = [], []; b = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device)\n",
        "            _, mu, _ = model(x)\n",
        "            mus.append(mu.cpu()); ys.append(y.cpu()); b += 1\n",
        "            if (max_batches is not None) and (b >= max_batches): break\n",
        "    return torch.cat(mus, 0), torch.cat(ys, 0)\n",
        "\n",
        "def collect_mu(model, loader, **kw): return collect_mu_y(model, loader, **kw)[0]\n",
        "\n",
        "def collect_mu_y_all(model, loader, device=DEVICE):\n",
        "    model.eval(); Zs, Ys = [], []\n",
        "    for x, y in loader:\n",
        "        x = x.to(device)\n",
        "        _, mu, _ = model(x)\n",
        "        Zs.append(mu.detach().cpu()); Ys.append(y.detach().cpu())\n",
        "    return torch.cat(Zs,0), torch.cat(Ys,0)\n",
        "\n",
        "def fit_ridge_classifier(Z, y, num_classes, lam=1e-2):\n",
        "    # Z: [N,d], y: [N], returns W: [d,C], b: [C]\n",
        "    N, d = Z.shape\n",
        "    C = num_classes\n",
        "    Y = torch.zeros(N, C, dtype=Z.dtype)\n",
        "    Y[torch.arange(N), y] = 1.0\n",
        "    Z1 = torch.cat([Z, torch.ones(N,1,dtype=Z.dtype)], dim=1)     # add bias\n",
        "    I = torch.eye(d+1, dtype=Z.dtype); I[-1,-1] = 0.0             # no reg on bias\n",
        "    A = Z1.T @ Z1 + lam * I\n",
        "    Wb = torch.linalg.solve(A, Z1.T @ Y)                          # (d+1) x C\n",
        "    W, b = Wb[:-1], Wb[-1]\n",
        "    return W, b\n",
        "\n",
        "@torch.no_grad()\n",
        "def probe_accuracy(student, tr_loader, te_loader, num_classes, lam=1e-2):\n",
        "    Z_tr, y_tr = collect_mu_y_all(student, tr_loader, device=DEVICE)\n",
        "    Z_te, y_te = collect_mu_y_all(student, te_loader, device=DEVICE)\n",
        "    W, b = fit_ridge_classifier(Z_tr, y_tr, num_classes, lam=lam)\n",
        "    logits_tr = Z_tr @ W + b\n",
        "    logits_te = Z_te @ W + b\n",
        "    acc_tr = (logits_tr.argmax(1) == y_tr).float().mean().item()\n",
        "    acc_te = (logits_te.argmax(1) == y_te).float().mean().item()\n",
        "    return acc_tr, acc_te\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_mi_gaussian_xy(A, B, eps=1e-5):\n",
        "    X = torch.cat([A, B], dim=1).double()\n",
        "    A = A.double(); B = B.double()\n",
        "    def cov(m):\n",
        "        c = torch.cov(m.T)\n",
        "        return c + eps * torch.eye(c.shape[0], dtype=c.dtype)\n",
        "    SA = cov(A); SB = cov(B); S = cov(X)\n",
        "    _, logdetA = torch.linalg.slogdet(SA)\n",
        "    _, logdetB = torch.linalg.slogdet(SB)\n",
        "    _, logdetS = torch.linalg.slogdet(S)\n",
        "    return 0.5 * (logdetA + logdetB - logdetS).item()\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_mi_teacher_student_on_loader(teacher, student, loader, eps=1e-5, max_batches=None):\n",
        "    zT = collect_mu(teacher, loader, device=DEVICE, max_batches=max_batches)\n",
        "    zS = collect_mu(student, loader, device=DEVICE, max_batches=max_batches)\n",
        "    return estimate_mi_gaussian_xy(zT, zS, eps=eps)\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_Ixz_upper(model, loader, device=DEVICE, max_batches=None):\n",
        "    model.eval(); kls = []; b = 0\n",
        "    for x, _ in loader:\n",
        "        x = x.to(device)\n",
        "        _, mu, logvar = model(x)\n",
        "        var = logvar.exp()\n",
        "        kl = 0.5 * (mu.pow(2) + var - logvar - 1.0).sum(dim=1)\n",
        "        kls.append(kl.detach().cpu()); b += 1\n",
        "        if (max_batches is not None) and (b >= max_batches): break\n",
        "    return torch.cat(kls, 0).mean().item()\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_Iyz_gaussian_plugin(model, loader, num_classes, eps=1e-5, max_batches=None):\n",
        "    Z, Y = collect_mu_y(model, loader, device=DEVICE, max_batches=max_batches)\n",
        "    Z = Z.double(); d = Z.shape[1]\n",
        "    def cov_eps(M):\n",
        "        C = torch.cov(M.T)\n",
        "        return C + eps * torch.eye(d, dtype=C.dtype)\n",
        "    Sig = cov_eps(Z); _, logdet = torch.linalg.slogdet(Sig)\n",
        "    H = 0.5 * (logdet + d * torch.log(torch.tensor(2.0 * torch.pi * torch.e, dtype=logdet.dtype)))\n",
        "    N = float(Z.shape[0]); Hy_avg = 0.0\n",
        "    for y in range(num_classes):\n",
        "        idx = (Y == y).nonzero(as_tuple=False).squeeze(-1)\n",
        "        if idx.numel() == 0: continue\n",
        "        Zy = Z[idx]\n",
        "        if Zy.shape[0] < d + 1:\n",
        "            var = Zy.var(dim=0, unbiased=True) + eps\n",
        "            logdet_y = torch.log(var).sum()\n",
        "        else:\n",
        "            Sigy = cov_eps(Zy); _, logdet_y = torch.linalg.slogdet(Sigy)\n",
        "        Hy = 0.5 * (logdet_y + d * torch.log(torch.tensor(2.0 * torch.pi * torch.e, dtype=logdet.dtype)))\n",
        "        py = idx.numel() / N\n",
        "        Hy_avg += py * Hy\n",
        "    return (H - Hy_avg).item()\n",
        "\n",
        "@torch.no_grad()\n",
        "def accuracy_on_loader(model, loader, device=DEVICE):\n",
        "    model.eval(); correct = total = 0\n",
        "    for x, y in loader:\n",
        "        x = x.to(device); y = y.to(device)\n",
        "        logits, _, _ = model(x)\n",
        "        pred = logits.argmax(1)\n",
        "        correct += (pred == y).sum().item(); total += y.size(0)\n",
        "    return correct / max(total, 1)\n",
        "\n",
        "class ConditionalGaussian(nn.Module):\n",
        "    def __init__(self, z_s_dim, z_t_dim, hidden=256):\n",
        "        super().__init__()\n",
        "        self.backbone = nn.Sequential(nn.Linear(z_s_dim, hidden), nn.ReLU(inplace=True),\n",
        "                                      nn.Linear(hidden, hidden), nn.ReLU(inplace=True))\n",
        "        self.mu = nn.Linear(hidden, z_t_dim)\n",
        "        self.logvar = nn.Linear(hidden, z_t_dim)\n",
        "    def forward(self, z_s):\n",
        "        h = self.backbone(z_s)\n",
        "        mu = self.mu(h)\n",
        "        logvar = self.logvar(h).clamp(-10.0, 10.0)\n",
        "        return mu, logvar\n",
        "\n",
        "def gaussian_nll(z, mu, logvar):\n",
        "    var = logvar.exp()\n",
        "    nll = 0.5 * (((z - mu) ** 2) / var + logvar + torch.log(torch.tensor(2.0 * torch.pi, device=z.device))).sum(dim=1)\n",
        "    return nll.mean()\n",
        "\n",
        "def kl_standard_normal(mu, logvar):\n",
        "    var = logvar.exp()\n",
        "    return 0.5 * (mu.pow(2) + var - logvar - 1.0).sum(dim=1).mean()\n",
        "\n",
        "ckpt = torch.load(\"teacher.pt\", map_location=DEVICE)\n",
        "teacher = VIB(IN_DIM, Z_DIM, NUM_CLASSES).to(DEVICE)\n",
        "teacher.load_state_dict(ckpt[\"model\"])\n",
        "teacher.eval()\n",
        "\n",
        "\n",
        "for p in teacher.parameters(): p.requires_grad_(False)\n",
        "# copy teacher's decoder to student\n",
        "student = VIB(IN_DIM, Z_DIM_STUDENT, NUM_CLASSES).to(DEVICE)\n",
        "student.classifier.load_state_dict(teacher.classifier.state_dict())\n",
        "q_head  = ConditionalGaussian(Z_DIM_STUDENT, Z_DIM).to(DEVICE)\n",
        "opt = torch.optim.Adam([\n",
        "    {\"params\": student.parameters(), \"lr\": LR_STUDENT},\n",
        "    {\"params\": q_head.parameters(),  \"lr\": LR_Q},\n",
        "])\n",
        "\n",
        "print(\"=== Teacher reference (before training) ===\")\n",
        "t_tr_acc = accuracy_on_loader(teacher, tr_loader)\n",
        "t_te_acc = accuracy_on_loader(teacher, te_loader)\n",
        "t_tr_Ixz = estimate_Ixz_upper(teacher, tr_loader)\n",
        "t_te_Ixz = estimate_Ixz_upper(teacher, te_loader)\n",
        "t_tr_Iyz = estimate_Iyz_gaussian_plugin(teacher, tr_loader, NUM_CLASSES, eps=EPS)\n",
        "t_te_Iyz = estimate_Iyz_gaussian_plugin(teacher, te_loader,  NUM_CLASSES, eps=EPS)\n",
        "print(f\"acc_train={t_tr_acc*100:.2f}% acc_val={t_te_acc*100:.2f}% | Ixz_train={t_tr_Ixz:.4f} Ixz_val={t_te_Ixz:.4f} | Iyz_train={t_tr_Iyz:.4f} Iyz_val={t_te_Iyz:.4f}\")\n",
        "\n",
        "mi_train_teacher_student, mi_val_teacher_student = [], []\n",
        "ixz_train, ixz_val, iyz_train, iyz_val = [], [], [], []\n",
        "acc_train_hist, acc_val_hist = [], []\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    student.train(); q_head.train()\n",
        "    pbar = tqdm(tr_loader, desc=f\"[MI + beta-Ixz] epoch {epoch}/{EPOCHS}\")\n",
        "    loss_sum = 0.0; n_batches = 0\n",
        "    for x, y in pbar:\n",
        "        if epoch == 1: break # measure things before train strart\n",
        "        x = x.to(DEVICE)\n",
        "        with torch.no_grad():\n",
        "            _, mu_T, logvar_T = teacher(x)\n",
        "            z_t = mu_T + (0.5 * logvar_T).exp() * torch.randn_like(mu_T)\n",
        "        _, mu_S, logvar_S = student(x)\n",
        "        z_s = mu_S + (0.5 * logvar_S).exp() * torch.randn_like(mu_S)\n",
        "        mu_q, logvar_q = q_head(z_s)\n",
        "        nll = gaussian_nll(z_t, mu_q, logvar_q)\n",
        "        kl_ixz = kl_standard_normal(mu_S, logvar_S)\n",
        "        loss = nll + BETA * kl_ixz\n",
        "        opt.zero_grad(); loss.backward(); opt.step()\n",
        "        loss_sum += float(loss.item()); n_batches += 1\n",
        "        pbar.set_postfix(loss=f\"{loss.item():.3f}\", nll=f\"{nll.item():.3f}\", kl=f\"{kl_ixz.item():.3f}\")\n",
        "    train_loss_epoch = loss_sum / max(n_batches, 1)\n",
        "\n",
        "    student.eval(); q_head.eval()\n",
        "    mi_tr = estimate_mi_teacher_student_on_loader(teacher, student, tr_loader, eps=EPS)\n",
        "    mi_v  = estimate_mi_teacher_student_on_loader(teacher, student, te_loader, eps=EPS)\n",
        "    ixz_tr = estimate_Ixz_upper(student, tr_loader)\n",
        "    ixz_v  = estimate_Ixz_upper(student, te_loader)\n",
        "    iyz_tr = estimate_Iyz_gaussian_plugin(student, tr_loader, NUM_CLASSES, eps=EPS)\n",
        "    iyz_v  = estimate_Iyz_gaussian_plugin(student, te_loader,  NUM_CLASSES, eps=EPS)\n",
        "    acc_tr, acc_te = probe_accuracy(student, tr_loader, te_loader, NUM_CLASSES, lam=1e-2)\n",
        "\n",
        "\n",
        "\n",
        "    mi_train_teacher_student.append(mi_tr); mi_val_teacher_student.append(mi_v)\n",
        "    ixz_train.append(ixz_tr); ixz_val.append(ixz_v)\n",
        "    iyz_train.append(iyz_tr); iyz_val.append(iyz_v)\n",
        "    acc_train_hist.append(acc_tr); acc_val_hist.append(acc_v)\n",
        "\n",
        "    print(f\"[epoch {epoch}] loss={train_loss_epoch:.4f} | beta={BETA:.4f} | \"\n",
        "          f\"probe_acc_tr={acc_tr*100:.2f}% probe_acc_val={acc_te*100:.2f}% | \"\n",
        "          f\"MI_tr={mi_tr:.4f} MI_val={mi_v:.4f} | Ixz_tr={ixz_tr:.4f} Ixz_val={ixz_v:.4f} | \"\n",
        "          f\"Iyz_tr={iyz_tr:.4f} Iyz_val={iyz_v:.4f}\")\n",
        "torch.save({\n",
        "    \"student\": student.state_dict(),\n",
        "    \"q_head\": q_head.state_dict(),\n",
        "    \"mi_train_teacher_student\": mi_train_teacher_student,\n",
        "    \"mi_val_teacher_student\": mi_val_teacher_student,\n",
        "    \"Ixz_train\": ixz_train,  \"Ixz_val\": ixz_val,\n",
        "    \"Iyz_train\": iyz_train,  \"Iyz_val\": iyz_val,\n",
        "    \"acc_train\": acc_train_hist, \"acc_val\": acc_val_hist,\n",
        "    \"beta\": BETA,\n",
        "    \"z_dim_student\": Z_DIM_STUDENT,\n",
        "}, \"student_mi_fixedbeta.pt\")\n",
        "\n",
        "print(\"Saved to student_mi_fixedbeta.pt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sn8wtJTdMpwY",
        "outputId": "73d7f499-1427-4a37-c67b-c08128f2e51f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Teacher reference (before training) ===\n",
            "acc_train=96.74% acc_val=94.70% | Ixz_train=4.1696 Ixz_val=4.1287 | Iyz_train=34.0816 Iyz_val=32.0867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[MI + beta-Ixz] epoch 1/100:   0%|          | 0/469 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 1] loss=0.0000 | beta=0.1000 | probe_acc_tr=76.85% probe_acc_val=77.03% | MI_tr=0.0249 MI_val=4.2134 | Ixz_tr=0.1109 Ixz_val=0.1116 | Iyz_tr=10.7890 Iyz_val=11.9203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[MI + beta-Ixz] epoch 2/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:04<00:00, 108.68it/s, kl=2.645, loss=91.362, nll=91.097]\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e40f2d393a0>Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e40f2d393a0>\n",
            "\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "        self._shutdown_workers()self._shutdown_workers()\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "        if w.is_alive():if w.is_alive():\n",
            "\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "        assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "AssertionErrorAssertionError: : can only test a child processcan only test a child process\n",
            "\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e40f2d393a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e40f2d393a0>^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "\n",
            "      File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "self._shutdown_workers()    \n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "\n",
            "      if w.is_alive():\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^\n",
            "^AssertionError^: ^^can only test a child process^\n",
            "^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e40f2d393a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e40f2d393a0>    \n",
            "if w.is_alive():Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "       self._shutdown_workers() \n",
            "   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "      ^if w.is_alive():^\n",
            "^ ^ ^ ^ ^ ^ ^ ^^^^^^\n",
            "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^ ^ ^ ^ ^ \n",
            "   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "      assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
            "    ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError^: ^can only test a child process^\n",
            "^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e40f2d393a0><function _MultiProcessingDataLoaderIter.__del__ at 0x7e40f2d393a0>\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "    self._shutdown_workers()    \n",
            "self._shutdown_workers()  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "\n",
            "      File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "if w.is_alive():    \n",
            "if w.is_alive(): \n",
            "            ^ ^^^^^^^^^^^^^^^^^^^^^^\n",
            "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "\n",
            "      File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
            "                    ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError\n",
            ": AssertionErrorcan only test a child process: \n",
            "can only test a child process\n",
            "Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e40f2d393a0><function _MultiProcessingDataLoaderIter.__del__ at 0x7e40f2d393a0>\n",
            "\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "        self._shutdown_workers()self._shutdown_workers()\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "        if w.is_alive():if w.is_alive():\n",
            "\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "        assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "AssertionErrorAssertionError: : can only test a child processcan only test a child process\n",
            "\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e40f2d393a0>\n",
            "Traceback (most recent call last):\n",
            "Exception ignored in:   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7e40f2d393a0>    \n",
            "self._shutdown_workers()Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "        self._shutdown_workers()if w.is_alive():\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "      if w.is_alive(): \n",
            "       ^ ^ ^ ^ ^^^^^^^^^^^^^^^^\n",
            "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "\n",
            "   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "      assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
            "              ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^^AssertionError^: ^can only test a child process^\n",
            "^\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 2] loss=90.9441 | beta=0.1000 | probe_acc_tr=90.86% probe_acc_val=90.87% | MI_tr=0.0229 MI_val=10.4558 | Ixz_tr=3.2203 Ixz_val=3.2560 | Iyz_tr=31.6276 Iyz_val=32.8686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[MI + beta-Ixz] epoch 3/100:   0%|          | 1/469 [00:00<00:47,  9.94it/s, kl=3.734, loss=90.881, nll=90.507]Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e40f2d393a0><function _MultiProcessingDataLoaderIter.__del__ at 0x7e40f2d393a0>\n",
            "\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "        self._shutdown_workers()self._shutdown_workers()\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "        if w.is_alive():if w.is_alive():\n",
            "\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "        assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "AssertionErrorAssertionError: : can only test a child processcan only test a child process\n",
            "\n",
            "[MI + beta-Ixz] epoch 3/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:04<00:00, 96.09it/s, kl=7.234, loss=89.001, nll=88.278] \n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e40f2d393a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  Exception ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7e40f2d393a0> \n",
            " Traceback (most recent call last):\n",
            "   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            " ^    ^self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "^^    ^if w.is_alive():^\n",
            "^ ^ ^ ^ \n",
            "    File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "     ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^ ^ ^ ^ ^ ^ ^ ^ ^ ^ \n",
            "   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^^\n",
            "^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError^: ^can only test a child process^\n",
            "^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 3] loss=89.8039 | beta=0.1000 | probe_acc_tr=95.92% probe_acc_val=95.82% | MI_tr=0.0245 MI_val=14.5709 | Ixz_tr=6.8249 Ixz_val=6.8719 | Iyz_tr=40.7864 Iyz_val=43.0284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[MI + beta-Ixz] epoch 4/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:03<00:00, 118.01it/s, kl=7.005, loss=88.287, nll=87.587]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 4] loss=88.7611 | beta=0.1000 | probe_acc_tr=97.46% probe_acc_val=96.99% | MI_tr=0.0248 MI_val=16.1854 | Ixz_tr=6.8957 Ixz_val=6.8879 | Iyz_tr=41.9783 Iyz_val=43.6861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[MI + beta-Ixz] epoch 5/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:04<00:00, 109.91it/s, kl=6.183, loss=88.829, nll=88.210]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 5] loss=88.3161 | beta=0.1000 | probe_acc_tr=98.00% probe_acc_val=97.13% | MI_tr=0.0259 MI_val=15.9927 | Ixz_tr=5.9953 Ixz_val=5.9931 | Iyz_tr=40.8467 Iyz_val=42.4801\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[MI + beta-Ixz] epoch 6/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:04<00:00, 108.96it/s, kl=5.356, loss=88.550, nll=88.014]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 6] loss=88.0870 | beta=0.1000 | probe_acc_tr=98.37% probe_acc_val=97.70% | MI_tr=0.0245 MI_val=16.0156 | Ixz_tr=5.4543 Ixz_val=5.4433 | Iyz_tr=39.2185 Iyz_val=40.3529\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[MI + beta-Ixz] epoch 7/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:04<00:00, 106.05it/s, kl=5.288, loss=87.831, nll=87.302]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 7] loss=88.0023 | beta=0.1000 | probe_acc_tr=98.58% probe_acc_val=97.73% | MI_tr=0.0258 MI_val=15.2419 | Ixz_tr=5.3170 Ixz_val=5.2936 | Iyz_tr=36.3153 Iyz_val=37.2967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[MI + beta-Ixz] epoch 8/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:04<00:00, 111.38it/s, kl=5.111, loss=87.473, nll=86.962]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 8] loss=87.9755 | beta=0.1000 | probe_acc_tr=98.65% probe_acc_val=97.64% | MI_tr=0.0248 MI_val=15.3209 | Ixz_tr=5.1878 Ixz_val=5.1765 | Iyz_tr=35.9893 Iyz_val=36.9982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[MI + beta-Ixz] epoch 9/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:04<00:00, 111.18it/s, kl=5.074, loss=87.891, nll=87.384]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 9] loss=87.8800 | beta=0.1000 | probe_acc_tr=98.69% probe_acc_val=97.67% | MI_tr=0.0253 MI_val=14.8996 | Ixz_tr=5.0750 Ixz_val=5.0555 | Iyz_tr=35.8760 Iyz_val=36.3373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[MI + beta-Ixz] epoch 10/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:04<00:00, 109.94it/s, kl=4.891, loss=87.150, nll=86.661]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 10] loss=87.8857 | beta=0.1000 | probe_acc_tr=98.86% probe_acc_val=97.69% | MI_tr=0.0249 MI_val=15.2010 | Ixz_tr=4.8836 Ixz_val=4.8621 | Iyz_tr=35.7140 Iyz_val=36.2916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[MI + beta-Ixz] epoch 11/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:04<00:00, 111.64it/s, kl=5.087, loss=87.012, nll=86.503]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 11] loss=87.8694 | beta=0.1000 | probe_acc_tr=98.83% probe_acc_val=97.70% | MI_tr=0.0241 MI_val=15.2494 | Ixz_tr=4.9737 Ixz_val=4.9642 | Iyz_tr=35.2638 Iyz_val=35.9471\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[MI + beta-Ixz] epoch 12/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:04<00:00, 109.76it/s, kl=5.015, loss=88.565, nll=88.064]\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "\n",
            "KeyboardInterrupt\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WxjJWqpxOGoc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}